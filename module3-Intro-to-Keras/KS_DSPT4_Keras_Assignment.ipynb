{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "# Import tensor flow and data set\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "\n",
    "\n",
    "# load the boston housing data into train/test sets.\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ] 15.2\n"
     ]
    }
   ],
   "source": [
    "# Exploring a sample of the features\n",
    "\n",
    "print(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
      "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
      "  0.8252202 ]\n"
     ]
    }
   ],
   "source": [
    "# Import sklearn tools for preprocessing, and use to normalize data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training set\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Call the transform method to scale both the training and testind data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Print a sample (sanity check)\n",
    "print(X_train_scaled[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.23247e+00 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.96900e+02\n",
      "  1.87200e+01]\n",
      " [2.17700e-02 8.25000e+01 2.03000e+00 ... 1.47000e+01 3.95380e+02\n",
      "  3.11000e+00]\n",
      " [4.89822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.75520e+02\n",
      "  3.26000e+00]\n",
      " ...\n",
      " [3.46600e-02 3.50000e+01 6.06000e+00 ... 1.69000e+01 3.62250e+02\n",
      "  7.83000e+00]\n",
      " [2.14918e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.61950e+02\n",
      "  1.57900e+01]\n",
      " [1.43900e-02 6.00000e+01 2.93000e+00 ... 1.56000e+01 3.76700e+02\n",
      "  4.38000e+00]]\n",
      "---\n",
      "[[1.23247e+00 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.96900e+02\n",
      "  1.87200e+01]\n",
      " [2.17700e-02 8.25000e+01 2.03000e+00 ... 1.47000e+01 3.95380e+02\n",
      "  3.11000e+00]\n",
      " [4.89822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.75520e+02\n",
      "  3.26000e+00]\n",
      " ...\n",
      " [3.46600e-02 3.50000e+01 6.06000e+00 ... 1.69000e+01 3.62250e+02\n",
      "  7.83000e+00]\n",
      " [2.14918e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 2.61950e+02\n",
      "  1.57900e+01]\n",
      " [1.43900e-02 6.00000e+01 2.93000e+00 ... 1.56000e+01 3.76700e+02\n",
      "  4.38000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Show the scale on all of the data\n",
    "\n",
    "print(X_train)\n",
    "print(\"---\")\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model and layer tools from keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 539.7458 - mean_squared_error: 539.7458 - val_loss: 565.5138 - val_mean_squared_error: 565.5138\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 465.4344 - mean_squared_error: 465.4344 - val_loss: 463.2373 - val_mean_squared_error: 463.2373\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 352.4573 - mean_squared_error: 352.4573 - val_loss: 308.9710 - val_mean_squared_error: 308.9710\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 203.2722 - mean_squared_error: 203.2722 - val_loss: 145.2720 - val_mean_squared_error: 145.2720\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 98.1193 - mean_squared_error: 98.1193 - val_loss: 94.3660 - val_mean_squared_error: 94.3660\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 81.8429 - mean_squared_error: 81.8429 - val_loss: 72.5251 - val_mean_squared_error: 72.5251\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 57.4040 - mean_squared_error: 57.4040 - val_loss: 58.8909 - val_mean_squared_error: 58.8909\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 45.6641 - mean_squared_error: 45.6641 - val_loss: 45.4712 - val_mean_squared_error: 45.4712\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 36.0021 - mean_squared_error: 36.0021 - val_loss: 36.6331 - val_mean_squared_error: 36.6331\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 29.8898 - mean_squared_error: 29.8898 - val_loss: 30.4556 - val_mean_squared_error: 30.4556\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 26.6211 - mean_squared_error: 26.6211 - val_loss: 27.4933 - val_mean_squared_error: 27.4933\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 24.0505 - mean_squared_error: 24.0505 - val_loss: 26.3072 - val_mean_squared_error: 26.3072\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 22.0346 - mean_squared_error: 22.0346 - val_loss: 23.7808 - val_mean_squared_error: 23.7808\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 20.7686 - mean_squared_error: 20.7686 - val_loss: 21.7622 - val_mean_squared_error: 21.7622\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 19.3817 - mean_squared_error: 19.3817 - val_loss: 20.9734 - val_mean_squared_error: 20.9734\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 18.0350 - mean_squared_error: 18.0350 - val_loss: 19.8406 - val_mean_squared_error: 19.8406\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 17.1496 - mean_squared_error: 17.1496 - val_loss: 18.8854 - val_mean_squared_error: 18.8854\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 16.2288 - mean_squared_error: 16.2288 - val_loss: 18.3764 - val_mean_squared_error: 18.3764\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 15.2583 - mean_squared_error: 15.2583 - val_loss: 17.2316 - val_mean_squared_error: 17.2316\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 14.5466 - mean_squared_error: 14.5466 - val_loss: 16.9439 - val_mean_squared_error: 16.9439\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 13.8875 - mean_squared_error: 13.8875 - val_loss: 16.1040 - val_mean_squared_error: 16.1040\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.2130 - mean_squared_error: 13.2130 - val_loss: 15.8033 - val_mean_squared_error: 15.8033\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 13.1302 - mean_squared_error: 13.1302 - val_loss: 15.2077 - val_mean_squared_error: 15.2077\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 12.1748 - mean_squared_error: 12.1748 - val_loss: 15.1447 - val_mean_squared_error: 15.1447\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 11.9458 - mean_squared_error: 11.9458 - val_loss: 14.8051 - val_mean_squared_error: 14.8051\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.4136 - mean_squared_error: 11.4136 - val_loss: 14.5231 - val_mean_squared_error: 14.5231\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 11.0319 - mean_squared_error: 11.0319 - val_loss: 14.3497 - val_mean_squared_error: 14.3497\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 10.6737 - mean_squared_error: 10.6737 - val_loss: 14.3436 - val_mean_squared_error: 14.3436\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.3510 - mean_squared_error: 10.3510 - val_loss: 14.1972 - val_mean_squared_error: 14.1972\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 10.2669 - mean_squared_error: 10.2669 - val_loss: 14.0706 - val_mean_squared_error: 14.0706\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.8793 - mean_squared_error: 9.8793 - val_loss: 14.1696 - val_mean_squared_error: 14.1696\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 9.7559 - mean_squared_error: 9.7559 - val_loss: 14.2325 - val_mean_squared_error: 14.2325\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.3458 - mean_squared_error: 9.3458 - val_loss: 14.1882 - val_mean_squared_error: 14.1882\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 9.2158 - mean_squared_error: 9.2158 - val_loss: 14.2881 - val_mean_squared_error: 14.2881\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8990 - mean_squared_error: 8.8990 - val_loss: 14.3950 - val_mean_squared_error: 14.3950\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.8170 - mean_squared_error: 8.8170 - val_loss: 14.4159 - val_mean_squared_error: 14.4159\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.5737 - mean_squared_error: 8.5737 - val_loss: 14.1288 - val_mean_squared_error: 14.1288\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5577 - mean_squared_error: 8.5577 - val_loss: 14.0932 - val_mean_squared_error: 14.0932\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.4957 - mean_squared_error: 8.4957 - val_loss: 14.3606 - val_mean_squared_error: 14.3606\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.5259 - mean_squared_error: 8.5259 - val_loss: 14.4954 - val_mean_squared_error: 14.4954\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2465 - mean_squared_error: 8.2465 - val_loss: 14.4143 - val_mean_squared_error: 14.4143\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.2702 - mean_squared_error: 8.2702 - val_loss: 14.1079 - val_mean_squared_error: 14.1079\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8.1686 - mean_squared_error: 8.1686 - val_loss: 13.6338 - val_mean_squared_error: 13.6338\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.9933 - mean_squared_error: 7.9933 - val_loss: 13.9315 - val_mean_squared_error: 13.9315\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.7348 - mean_squared_error: 7.7348 - val_loss: 14.2299 - val_mean_squared_error: 14.2299\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.6938 - mean_squared_error: 7.6938 - val_loss: 14.5491 - val_mean_squared_error: 14.5491\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.4716 - mean_squared_error: 7.4716 - val_loss: 14.4390 - val_mean_squared_error: 14.4390\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.5526 - mean_squared_error: 7.5526 - val_loss: 14.0638 - val_mean_squared_error: 14.0638\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 7.3477 - mean_squared_error: 7.3477 - val_loss: 14.4570 - val_mean_squared_error: 14.4570\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.1351 - mean_squared_error: 7.1351 - val_loss: 14.3972 - val_mean_squared_error: 14.3972\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0855 - mean_squared_error: 7.0855 - val_loss: 14.3647 - val_mean_squared_error: 14.3647\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0287 - mean_squared_error: 7.0287 - val_loss: 14.7967 - val_mean_squared_error: 14.7967\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 7.1138 - mean_squared_error: 7.1138 - val_loss: 14.2643 - val_mean_squared_error: 14.2643\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0402 - mean_squared_error: 7.0402 - val_loss: 13.9265 - val_mean_squared_error: 13.9265\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.9176 - mean_squared_error: 6.9176 - val_loss: 14.4206 - val_mean_squared_error: 14.4206\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.8412 - mean_squared_error: 6.8412 - val_loss: 14.5935 - val_mean_squared_error: 14.5935\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.9657 - mean_squared_error: 6.9657 - val_loss: 14.7267 - val_mean_squared_error: 14.7267\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7922 - mean_squared_error: 6.7922 - val_loss: 14.7072 - val_mean_squared_error: 14.7072\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.8108 - mean_squared_error: 6.8108 - val_loss: 14.3841 - val_mean_squared_error: 14.3841\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.8354 - mean_squared_error: 6.8354 - val_loss: 14.8186 - val_mean_squared_error: 14.8186\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.6183 - mean_squared_error: 6.6183 - val_loss: 14.7711 - val_mean_squared_error: 14.7711\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.6241 - mean_squared_error: 6.6241 - val_loss: 14.2407 - val_mean_squared_error: 14.2407\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 6.4671 - mean_squared_error: 6.4671 - val_loss: 14.6101 - val_mean_squared_error: 14.6101\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7125 - mean_squared_error: 6.7125 - val_loss: 14.6455 - val_mean_squared_error: 14.6455\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.3123 - mean_squared_error: 6.3123 - val_loss: 14.5784 - val_mean_squared_error: 14.5784\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.4374 - mean_squared_error: 6.4374 - val_loss: 14.6045 - val_mean_squared_error: 14.6045\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.5433 - mean_squared_error: 6.5433 - val_loss: 14.4500 - val_mean_squared_error: 14.4500\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.0099 - mean_squared_error: 7.0099 - val_loss: 15.2591 - val_mean_squared_error: 15.2591\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.7654 - mean_squared_error: 6.7654 - val_loss: 14.7024 - val_mean_squared_error: 14.7024\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7.2820 - mean_squared_error: 7.2820 - val_loss: 14.3295 - val_mean_squared_error: 14.3295\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 6.4262 - mean_squared_error: 6.4262 - val_loss: 15.8722 - val_mean_squared_error: 15.8722\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6.1992 - mean_squared_error: 6.1992 - val_loss: 15.2303 - val_mean_squared_error: 15.2303\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9546 - mean_squared_error: 5.9546 - val_loss: 15.7480 - val_mean_squared_error: 15.7480\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9428 - mean_squared_error: 5.9428 - val_loss: 15.4661 - val_mean_squared_error: 15.4661\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.9382 - mean_squared_error: 5.9382 - val_loss: 15.4048 - val_mean_squared_error: 15.4048\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.7462 - mean_squared_error: 5.7462 - val_loss: 15.1257 - val_mean_squared_error: 15.1257\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5.8057 - mean_squared_error: 5.8057 - val_loss: 15.4911 - val_mean_squared_error: 15.4911\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.7594 - mean_squared_error: 5.7594 - val_loss: 15.4097 - val_mean_squared_error: 15.4097\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.8753 - mean_squared_error: 5.8753 - val_loss: 15.5696 - val_mean_squared_error: 15.5696\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.8488 - mean_squared_error: 5.8488 - val_loss: 15.3927 - val_mean_squared_error: 15.3927\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.5610 - mean_squared_error: 5.5610 - val_loss: 15.3350 - val_mean_squared_error: 15.3350\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.5846 - mean_squared_error: 5.5846 - val_loss: 15.3111 - val_mean_squared_error: 15.3111\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4719 - mean_squared_error: 5.4719 - val_loss: 15.6019 - val_mean_squared_error: 15.6019\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.6595 - mean_squared_error: 5.6595 - val_loss: 15.2634 - val_mean_squared_error: 15.2634\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.5463 - mean_squared_error: 5.5463 - val_loss: 15.2420 - val_mean_squared_error: 15.2420\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.4292 - mean_squared_error: 5.4292 - val_loss: 14.8136 - val_mean_squared_error: 14.8136\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.3588 - mean_squared_error: 5.3588 - val_loss: 15.4685 - val_mean_squared_error: 15.4685\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.2986 - mean_squared_error: 5.2986 - val_loss: 14.6519 - val_mean_squared_error: 14.6519\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3126 - mean_squared_error: 5.3126 - val_loss: 14.6701 - val_mean_squared_error: 14.6701\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.3683 - mean_squared_error: 5.3683 - val_loss: 15.0293 - val_mean_squared_error: 15.0293\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.1505 - mean_squared_error: 5.1505 - val_loss: 14.7373 - val_mean_squared_error: 14.7373\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1671 - mean_squared_error: 5.1671 - val_loss: 14.7863 - val_mean_squared_error: 14.7863\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.1718 - mean_squared_error: 5.1718 - val_loss: 14.8046 - val_mean_squared_error: 14.8046\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0449 - mean_squared_error: 5.0449 - val_loss: 14.8644 - val_mean_squared_error: 14.8644\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.0817 - mean_squared_error: 5.0817 - val_loss: 15.2647 - val_mean_squared_error: 15.2647\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1604 - mean_squared_error: 5.1604 - val_loss: 15.0678 - val_mean_squared_error: 15.0678\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.8478 - mean_squared_error: 4.8478 - val_loss: 14.6650 - val_mean_squared_error: 14.6650\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0508 - mean_squared_error: 5.0508 - val_loss: 14.9882 - val_mean_squared_error: 14.9882\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.8607 - mean_squared_error: 4.8607 - val_loss: 14.6670 - val_mean_squared_error: 14.6670\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.7848 - mean_squared_error: 4.7848 - val_loss: 14.8014 - val_mean_squared_error: 14.8014\n"
     ]
    }
   ],
   "source": [
    "# Instantiated a model object\n",
    "model1 = Sequential()\n",
    "\n",
    "# Added hidden layers to my model with activation features\n",
    "model1.add(Dense(50, activation='relu', autocast=False))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Added output Layer with activation features\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Compiling model\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "\n",
    "# Call the fit method to start training include validation set\n",
    "history = model1.fit(X_train_scaled, y_train, validation_split=0.2, batch_size=35, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [539.7457885742188,\n",
       "  465.4343566894531,\n",
       "  352.457275390625,\n",
       "  203.27215576171875,\n",
       "  98.11927032470703,\n",
       "  81.84286499023438,\n",
       "  57.403968811035156,\n",
       "  45.66410827636719,\n",
       "  36.0020751953125,\n",
       "  29.889768600463867,\n",
       "  26.621061325073242,\n",
       "  24.050508499145508,\n",
       "  22.034648895263672,\n",
       "  20.768611907958984,\n",
       "  19.38173484802246,\n",
       "  18.03502655029297,\n",
       "  17.149572372436523,\n",
       "  16.22880744934082,\n",
       "  15.258318901062012,\n",
       "  14.546606063842773,\n",
       "  13.887463569641113,\n",
       "  13.212996482849121,\n",
       "  13.130159378051758,\n",
       "  12.174786567687988,\n",
       "  11.94579029083252,\n",
       "  11.41360092163086,\n",
       "  11.031903266906738,\n",
       "  10.673742294311523,\n",
       "  10.350981712341309,\n",
       "  10.266945838928223,\n",
       "  9.879339218139648,\n",
       "  9.755894660949707,\n",
       "  9.345799446105957,\n",
       "  9.21578311920166,\n",
       "  8.898969650268555,\n",
       "  8.817032814025879,\n",
       "  8.573701858520508,\n",
       "  8.557701110839844,\n",
       "  8.495697975158691,\n",
       "  8.525883674621582,\n",
       "  8.246527671813965,\n",
       "  8.27022647857666,\n",
       "  8.168553352355957,\n",
       "  7.993259429931641,\n",
       "  7.734795093536377,\n",
       "  7.693812847137451,\n",
       "  7.471558094024658,\n",
       "  7.552562713623047,\n",
       "  7.347716808319092,\n",
       "  7.135105609893799,\n",
       "  7.085521697998047,\n",
       "  7.028712749481201,\n",
       "  7.113783359527588,\n",
       "  7.040191173553467,\n",
       "  6.9175567626953125,\n",
       "  6.841175556182861,\n",
       "  6.965693473815918,\n",
       "  6.792161464691162,\n",
       "  6.810842990875244,\n",
       "  6.835446834564209,\n",
       "  6.618253231048584,\n",
       "  6.624128341674805,\n",
       "  6.4670515060424805,\n",
       "  6.712465286254883,\n",
       "  6.312320232391357,\n",
       "  6.437373638153076,\n",
       "  6.543254375457764,\n",
       "  7.009945392608643,\n",
       "  6.76542329788208,\n",
       "  7.282036781311035,\n",
       "  6.426152229309082,\n",
       "  6.199202537536621,\n",
       "  5.954639911651611,\n",
       "  5.942842960357666,\n",
       "  5.938237190246582,\n",
       "  5.746211528778076,\n",
       "  5.805700778961182,\n",
       "  5.759364128112793,\n",
       "  5.8752522468566895,\n",
       "  5.848804473876953,\n",
       "  5.561018466949463,\n",
       "  5.58456563949585,\n",
       "  5.471887588500977,\n",
       "  5.659483909606934,\n",
       "  5.5462727546691895,\n",
       "  5.429167747497559,\n",
       "  5.358785629272461,\n",
       "  5.2985615730285645,\n",
       "  5.31260347366333,\n",
       "  5.368329048156738,\n",
       "  5.150484085083008,\n",
       "  5.167084217071533,\n",
       "  5.171830177307129,\n",
       "  5.044891834259033,\n",
       "  5.081709861755371,\n",
       "  5.160366535186768,\n",
       "  4.847814559936523,\n",
       "  5.050826549530029,\n",
       "  4.860743522644043,\n",
       "  4.784750938415527],\n",
       " 'mean_squared_error': [539.7457885742188,\n",
       "  465.4343566894531,\n",
       "  352.457275390625,\n",
       "  203.27215576171875,\n",
       "  98.11927032470703,\n",
       "  81.84286499023438,\n",
       "  57.403968811035156,\n",
       "  45.66410827636719,\n",
       "  36.0020751953125,\n",
       "  29.889768600463867,\n",
       "  26.621061325073242,\n",
       "  24.050508499145508,\n",
       "  22.034648895263672,\n",
       "  20.768611907958984,\n",
       "  19.38173484802246,\n",
       "  18.03502655029297,\n",
       "  17.149572372436523,\n",
       "  16.22880744934082,\n",
       "  15.258318901062012,\n",
       "  14.546606063842773,\n",
       "  13.887463569641113,\n",
       "  13.212996482849121,\n",
       "  13.130159378051758,\n",
       "  12.174786567687988,\n",
       "  11.945791244506836,\n",
       "  11.41360092163086,\n",
       "  11.031903266906738,\n",
       "  10.673742294311523,\n",
       "  10.350981712341309,\n",
       "  10.266945838928223,\n",
       "  9.879339218139648,\n",
       "  9.755894660949707,\n",
       "  9.345799446105957,\n",
       "  9.21578311920166,\n",
       "  8.898969650268555,\n",
       "  8.817032814025879,\n",
       "  8.573701858520508,\n",
       "  8.557701110839844,\n",
       "  8.495697975158691,\n",
       "  8.525883674621582,\n",
       "  8.246527671813965,\n",
       "  8.27022647857666,\n",
       "  8.168553352355957,\n",
       "  7.993259429931641,\n",
       "  7.734796047210693,\n",
       "  7.693812847137451,\n",
       "  7.471558094024658,\n",
       "  7.552562713623047,\n",
       "  7.347716808319092,\n",
       "  7.135105609893799,\n",
       "  7.085521697998047,\n",
       "  7.028712749481201,\n",
       "  7.113783359527588,\n",
       "  7.040191173553467,\n",
       "  6.9175567626953125,\n",
       "  6.841175556182861,\n",
       "  6.965693473815918,\n",
       "  6.792161464691162,\n",
       "  6.810842990875244,\n",
       "  6.835446834564209,\n",
       "  6.618252277374268,\n",
       "  6.624128341674805,\n",
       "  6.4670515060424805,\n",
       "  6.712465286254883,\n",
       "  6.312320232391357,\n",
       "  6.437373638153076,\n",
       "  6.543254375457764,\n",
       "  7.009945392608643,\n",
       "  6.76542329788208,\n",
       "  7.282036781311035,\n",
       "  6.426152229309082,\n",
       "  6.199202537536621,\n",
       "  5.954639911651611,\n",
       "  5.942842960357666,\n",
       "  5.938237190246582,\n",
       "  5.746211528778076,\n",
       "  5.805700778961182,\n",
       "  5.759364128112793,\n",
       "  5.8752522468566895,\n",
       "  5.848804473876953,\n",
       "  5.561018466949463,\n",
       "  5.58456563949585,\n",
       "  5.471887588500977,\n",
       "  5.659484386444092,\n",
       "  5.5462727546691895,\n",
       "  5.429167747497559,\n",
       "  5.358785629272461,\n",
       "  5.2985615730285645,\n",
       "  5.31260347366333,\n",
       "  5.368329048156738,\n",
       "  5.150484085083008,\n",
       "  5.167084217071533,\n",
       "  5.171830177307129,\n",
       "  5.044890880584717,\n",
       "  5.081709861755371,\n",
       "  5.160366535186768,\n",
       "  4.847814559936523,\n",
       "  5.050826549530029,\n",
       "  4.860743522644043,\n",
       "  4.784750938415527],\n",
       " 'val_loss': [565.5137939453125,\n",
       "  463.2373046875,\n",
       "  308.9709777832031,\n",
       "  145.27195739746094,\n",
       "  94.36602020263672,\n",
       "  72.52513122558594,\n",
       "  58.89089584350586,\n",
       "  45.47117614746094,\n",
       "  36.633056640625,\n",
       "  30.45564842224121,\n",
       "  27.49327278137207,\n",
       "  26.307239532470703,\n",
       "  23.78080177307129,\n",
       "  21.762235641479492,\n",
       "  20.973430633544922,\n",
       "  19.840579986572266,\n",
       "  18.88543701171875,\n",
       "  18.376428604125977,\n",
       "  17.23163604736328,\n",
       "  16.943878173828125,\n",
       "  16.10402488708496,\n",
       "  15.803303718566895,\n",
       "  15.207650184631348,\n",
       "  15.144683837890625,\n",
       "  14.805059432983398,\n",
       "  14.523146629333496,\n",
       "  14.349669456481934,\n",
       "  14.34360122680664,\n",
       "  14.197227478027344,\n",
       "  14.070600509643555,\n",
       "  14.169553756713867,\n",
       "  14.232504844665527,\n",
       "  14.188152313232422,\n",
       "  14.288081169128418,\n",
       "  14.394968032836914,\n",
       "  14.41589069366455,\n",
       "  14.128775596618652,\n",
       "  14.093192100524902,\n",
       "  14.360583305358887,\n",
       "  14.495373725891113,\n",
       "  14.414258003234863,\n",
       "  14.107879638671875,\n",
       "  13.633846282958984,\n",
       "  13.931451797485352,\n",
       "  14.22989273071289,\n",
       "  14.54909610748291,\n",
       "  14.43896770477295,\n",
       "  14.063782691955566,\n",
       "  14.45700740814209,\n",
       "  14.397195816040039,\n",
       "  14.364665031433105,\n",
       "  14.79674243927002,\n",
       "  14.264274597167969,\n",
       "  13.926534652709961,\n",
       "  14.420602798461914,\n",
       "  14.593505859375,\n",
       "  14.72666072845459,\n",
       "  14.707161903381348,\n",
       "  14.384105682373047,\n",
       "  14.818642616271973,\n",
       "  14.771133422851562,\n",
       "  14.240717887878418,\n",
       "  14.610149383544922,\n",
       "  14.64549446105957,\n",
       "  14.578418731689453,\n",
       "  14.604508399963379,\n",
       "  14.449974060058594,\n",
       "  15.259132385253906,\n",
       "  14.702397346496582,\n",
       "  14.329538345336914,\n",
       "  15.872230529785156,\n",
       "  15.23031997680664,\n",
       "  15.748018264770508,\n",
       "  15.466108322143555,\n",
       "  15.40481185913086,\n",
       "  15.125673294067383,\n",
       "  15.491143226623535,\n",
       "  15.409688949584961,\n",
       "  15.569585800170898,\n",
       "  15.392692565917969,\n",
       "  15.33504867553711,\n",
       "  15.311125755310059,\n",
       "  15.601905822753906,\n",
       "  15.263401985168457,\n",
       "  15.241969108581543,\n",
       "  14.8135986328125,\n",
       "  15.46847915649414,\n",
       "  14.651930809020996,\n",
       "  14.670132637023926,\n",
       "  15.029260635375977,\n",
       "  14.73732852935791,\n",
       "  14.786346435546875,\n",
       "  14.804648399353027,\n",
       "  14.86439323425293,\n",
       "  15.264747619628906,\n",
       "  15.067780494689941,\n",
       "  14.66502857208252,\n",
       "  14.988153457641602,\n",
       "  14.666987419128418,\n",
       "  14.801365852355957],\n",
       " 'val_mean_squared_error': [565.5137939453125,\n",
       "  463.2373046875,\n",
       "  308.9709777832031,\n",
       "  145.27195739746094,\n",
       "  94.36602020263672,\n",
       "  72.5251235961914,\n",
       "  58.89089584350586,\n",
       "  45.47117614746094,\n",
       "  36.633056640625,\n",
       "  30.45564842224121,\n",
       "  27.49327278137207,\n",
       "  26.307239532470703,\n",
       "  23.78080177307129,\n",
       "  21.76223373413086,\n",
       "  20.973430633544922,\n",
       "  19.840579986572266,\n",
       "  18.88543701171875,\n",
       "  18.376428604125977,\n",
       "  17.23163604736328,\n",
       "  16.943878173828125,\n",
       "  16.10402488708496,\n",
       "  15.803303718566895,\n",
       "  15.207650184631348,\n",
       "  15.144683837890625,\n",
       "  14.805059432983398,\n",
       "  14.523146629333496,\n",
       "  14.349669456481934,\n",
       "  14.34360122680664,\n",
       "  14.197227478027344,\n",
       "  14.070600509643555,\n",
       "  14.169553756713867,\n",
       "  14.232504844665527,\n",
       "  14.188152313232422,\n",
       "  14.288081169128418,\n",
       "  14.394968032836914,\n",
       "  14.41589069366455,\n",
       "  14.128775596618652,\n",
       "  14.093192100524902,\n",
       "  14.360583305358887,\n",
       "  14.495373725891113,\n",
       "  14.414258003234863,\n",
       "  14.107879638671875,\n",
       "  13.633846282958984,\n",
       "  13.931451797485352,\n",
       "  14.22989273071289,\n",
       "  14.549098014831543,\n",
       "  14.43896770477295,\n",
       "  14.063782691955566,\n",
       "  14.45700740814209,\n",
       "  14.397195816040039,\n",
       "  14.364663124084473,\n",
       "  14.79674243927002,\n",
       "  14.264274597167969,\n",
       "  13.926534652709961,\n",
       "  14.420602798461914,\n",
       "  14.593505859375,\n",
       "  14.72666072845459,\n",
       "  14.707161903381348,\n",
       "  14.384105682373047,\n",
       "  14.818642616271973,\n",
       "  14.771133422851562,\n",
       "  14.240717887878418,\n",
       "  14.610149383544922,\n",
       "  14.64549446105957,\n",
       "  14.578418731689453,\n",
       "  14.604508399963379,\n",
       "  14.449974060058594,\n",
       "  15.259132385253906,\n",
       "  14.702397346496582,\n",
       "  14.329538345336914,\n",
       "  15.872230529785156,\n",
       "  15.23031997680664,\n",
       "  15.748018264770508,\n",
       "  15.466108322143555,\n",
       "  15.404810905456543,\n",
       "  15.125673294067383,\n",
       "  15.491143226623535,\n",
       "  15.409688949584961,\n",
       "  15.569584846496582,\n",
       "  15.392691612243652,\n",
       "  15.33504867553711,\n",
       "  15.311125755310059,\n",
       "  15.601905822753906,\n",
       "  15.263401985168457,\n",
       "  15.241969108581543,\n",
       "  14.8135986328125,\n",
       "  15.46847915649414,\n",
       "  14.651930809020996,\n",
       "  14.670132637023926,\n",
       "  15.029260635375977,\n",
       "  14.73732852935791,\n",
       "  14.786346435546875,\n",
       "  14.804648399353027,\n",
       "  14.86439323425293,\n",
       "  15.264747619628906,\n",
       "  15.067780494689941,\n",
       "  14.66502857208252,\n",
       "  14.988153457641602,\n",
       "  14.66698932647705,\n",
       "  14.801365852355957]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the tracking history of the model\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2370747.5000 - mean_squared_error: 2370747.5000\n"
     ]
    }
   ],
   "source": [
    "# evalute model to get test scores. (loss = MSE at compile time)\n",
    "scores = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the loss-MSE value.\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n",
      "Test Mean Squared Error: 23.195599256422973\n",
      "Test Mean Absolute Error: 3.4641858124067166\n",
      "Test R^2: 0.7213535934621553\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# set the linear regression model.\n",
    "L_model = LinearRegression()\n",
    "\n",
    "# fit the model on the data.\n",
    "L_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# label and create them model.predict(X_test).\n",
    "y_pred = L_model.predict(X_test_scaled)\n",
    "\n",
    "# get the regression metrics.\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# show all the regression metric results.\n",
    "print(X_train_scaled.shape, X_test.shape)\n",
    "print('Test Mean Squared Error:', test_mse)\n",
    "print('Test Mean Absolute Error:', test_mae)\n",
    "print('Test R^2:', test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# load the mnist data.\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1df74320a48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports.\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Plot what row 2 looks like.\n",
    "plt.imshow(X_train[1], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Variable Types\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "# Correct Encoding on Y\n",
    "# What softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 932us/step - loss: 0.5974 - accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 857us/step - loss: 0.4615 - accuracy: 0.8435\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 888us/step - loss: 0.4351 - accuracy: 0.8495\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 827us/step - loss: 0.4221 - accuracy: 0.8550\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 852us/step - loss: 0.4121 - accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 846us/step - loss: 0.4067 - accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 805us/step - loss: 0.4028 - accuracy: 0.8609\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 911us/step - loss: 0.3980 - accuracy: 0.8620\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.3948 - accuracy: 0.8635\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 936us/step - loss: 0.3914 - accuracy: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df71f780c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3889 - accuracy: 0.8635 - val_loss: 0.4430 - val_accuracy: 0.8443\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3880 - accuracy: 0.8648 - val_loss: 0.4706 - val_accuracy: 0.8350\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 2s 994us/step - loss: 0.3853 - accuracy: 0.8653 - val_loss: 0.4433 - val_accuracy: 0.8446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df0037d488>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          epochs=3, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 716us/step - loss: 0.4433 - accuracy: 0.8446\n",
      "\n",
      "\n",
      "Validation Data Metrics:\n",
      "loss: 0.44326552748680115\n",
      "accuracy: 84.46000218391418\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n\")\n",
    "print(\"Validation Data Metrics:\")\n",
    "print(f\"{model.metrics_names[0]}: {scores[0]}\")\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kjshe\\\\OneDrive\\\\Desktop\\\\DS-Unit-4-Sprint-2-Neural-Networks\\\\module3-Intro-to-Keras'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5031 - accuracy: 0.8218 - val_loss: 0.4226 - val_accuracy: 0.8472\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3755 - accuracy: 0.8634 - val_loss: 0.4036 - val_accuracy: 0.8550\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3358 - accuracy: 0.8787 - val_loss: 0.3665 - val_accuracy: 0.8661\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.8849 - val_loss: 0.3702 - val_accuracy: 0.8685\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2931 - accuracy: 0.8928 - val_loss: 0.3736 - val_accuracy: 0.8642\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(x=X_train, \n",
    "                    y=y_train, \n",
    "                    epochs=5, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 42224), started 1 day, 3:25:01 ago. (Use '!kill 42224' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8a3fd9ce9a372cf7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8a3fd9ce9a372cf7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super simple NN for fashion_mnist date without activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.8138\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4562 - accuracy: 0.8426\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4406 - accuracy: 0.8456\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4334 - accuracy: 0.8489\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4235 - accuracy: 0.8508\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4180 - accuracy: 0.8526\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4140 - accuracy: 0.8556\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4088 - accuracy: 0.8571\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4077 - accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4036 - accuracy: 0.8575\n",
      "313/313 [==============================] - 0s 879us/step - loss: 0.4784 - accuracy: 0.8347\n",
      "Test Accuracy: 0.8346999883651733\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# Load the Data\n",
    "(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "# Build the model with no activation functions\n",
    "model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                             tf.keras.layers.Dense(128),\n",
    "                             tf.keras.layers.Dense(10)])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(train_images, train_labels,epochs=10, callbacks=[tensorboard_callback])\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
    "\n",
    "# Print Test Accuracy\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 42224), started 1 day, 3:25:50 ago. (Use '!kill 42224' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2a4fa1249ccf0b96\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2a4fa1249ccf0b96\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
